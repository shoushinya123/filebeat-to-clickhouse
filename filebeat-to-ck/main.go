package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"net/url"
	"os"
	"strings"
	"time"

	"github.com/gin-gonic/gin"
	"gopkg.in/yaml.v3"
)

// Config é…ç½®ç»“æ„
type Config struct {
	Server struct {
		Host string `yaml:"host"`
		Port int    `yaml:"port"`
	} `yaml:"server"`
	ClickHouse struct {
		Host     string `yaml:"host"`
		Port     int    `yaml:"port"`
		Database string `yaml:"database"`
		Table    string `yaml:"table"`
		User     string `yaml:"user"`
		Password string `yaml:"password"`
	} `yaml:"clickhouse"`
	Inputs struct {
		Elasticsearch struct {
			Enabled bool `yaml:"enabled"`
			Port    int  `yaml:"port"`
		} `yaml:"elasticsearch"`
		Logstash struct {
			Enabled  bool   `yaml:"enabled"`
			Port     int    `yaml:"port"`
			Protocol string `yaml:"protocol"`
		} `yaml:"logstash"`
		Kafka struct {
			Enabled    bool     `yaml:"enabled"`
			Brokers    []string `yaml:"brokers"`
			Topics     []string `yaml:"topics"`
			GroupID    string   `yaml:"group_id"`
			AutoCommit bool     `yaml:"auto_commit"`
		} `yaml:"kafka"`
		Redis struct {
			Enabled  bool   `yaml:"enabled"`
			Address  string `yaml:"address"`
			Password string `yaml:"password"`
			Mode     string `yaml:"mode"` // list or pubsub
			Key      string `yaml:"key"`
		} `yaml:"redis"`
		File struct {
			Enabled bool     `yaml:"enabled"`
			Paths   []string `yaml:"paths"`
			Follow  bool     `yaml:"follow"`
		} `yaml:"file"`
		TCP struct {
			Enabled bool   `yaml:"enabled"`
			Port    int    `yaml:"port"`
			Format  string `yaml:"format"`
		} `yaml:"tcp"`
	} `yaml:"inputs"`
	LogLevel string `yaml:"log_level"`
}

// FilebeatEvent Filebeat äº‹ä»¶ç»“æ„
type FilebeatEvent struct {
	Timestamp interface{}            `json:"@timestamp"` // å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ—¶é—´å¯¹è±¡
	Message   string                 `json:"message"`
	Fields    map[string]interface{} `json:"fields,omitempty"`
	Container map[string]interface{} `json:"container,omitempty"`
	Host      map[string]interface{} `json:"host,omitempty"`
	Docker    map[string]interface{} `json:"docker,omitempty"`
	Agent     map[string]interface{} `json:"agent,omitempty"`
	Log       map[string]interface{} `json:"log,omitempty"`
	// æ”¯æŒä»»æ„å…¶ä»–å­—æ®µ
	Extra map[string]interface{} `json:"-"`
}

// GetTimestamp è·å–æ—¶é—´æˆ³
func (e *FilebeatEvent) GetTimestamp() time.Time {
	if e.Timestamp == nil {
		return time.Now()
	}
	
	switch v := e.Timestamp.(type) {
	case string:
		// å°è¯•å¤šç§æ—¶é—´æ ¼å¼
		formats := []string{
			time.RFC3339,
			time.RFC3339Nano,
			"2006-01-02T15:04:05.000Z",
			"2006-01-02T15:04:05Z",
			"2006-01-02 15:04:05",
		}
		for _, format := range formats {
			if t, err := time.Parse(format, v); err == nil {
				return t
			}
		}
		return time.Now()
	case time.Time:
		return v
	default:
		return time.Now()
	}
}

// ElasticsearchBulkRequest Elasticsearch bulk API è¯·æ±‚æ ¼å¼
type ElasticsearchBulkRequest struct {
	Index struct {
		Index string `json:"_index"`
		Type  string `json:"_type,omitempty"`
		ID    string `json:"_id,omitempty"`
	} `json:"index,omitempty"`
	Create struct {
		Index string `json:"_index"`
		Type  string `json:"_type,omitempty"`
		ID    string `json:"_id,omitempty"`
	} `json:"create,omitempty"`
	Delete struct {
		Index string `json:"_index"`
		Type  string `json:"_type,omitempty"`
		ID    string `json:"_id,omitempty"`
	} `json:"delete,omitempty"`
	Update struct {
		Index string `json:"_index"`
		Type  string `json:"_type,omitempty"`
		ID    string `json:"_id,omitempty"`
	} `json:"update,omitempty"`
	Doc interface{} `json:"doc,omitempty"`
}

var config Config

func main() {
	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		log.Fatalf("åŠ è½½é…ç½®å¤±è´¥: %v", err)
	}

	// è®¾ç½®æ—¥å¿—çº§åˆ«
	if config.LogLevel == "debug" {
		log.SetFlags(log.LstdFlags | log.Lshortfile)
	}

	// è®¾ç½® Gin æ¨¡å¼
	if config.LogLevel != "debug" {
		gin.SetMode(gin.ReleaseMode)
	}

	// åˆ›å»ºè·¯ç”±
	r := gin.Default()

	// å¥åº·æ£€æŸ¥
	r.GET("/health", healthCheck)
	r.GET("/", healthCheck)

	// Elasticsearch å…¼å®¹æ¥å£ï¼ˆæ”¯æŒ output.elasticsearchï¼‰
	r.POST("/_bulk", handleBulk)
	r.POST("/:index/_bulk", handleBulk)
	r.POST("/:index/:type/_bulk", handleBulk)

	// Logstash å…¼å®¹æ¥å£ï¼ˆæ”¯æŒ output.logstashï¼‰
	r.POST("/", handleLogstash)  // Logstash HTTP è¾“å‡º
	r.Any("/logstash", handleLogstash)

	// ç›´æ¥ JSON æ¥æ”¶æ¥å£ï¼ˆé€šç”¨ï¼‰
	r.POST("/events", handleEvents)
	r.POST("/filebeat", handleFilebeat)
	r.POST("/ingest", handleFilebeat)  // é€šç”¨æ¥æ”¶ç«¯ç‚¹

	// å¯åŠ¨ HTTP æœåŠ¡å™¨ï¼ˆæ”¯æŒ Elasticsearch å’Œ Logstash HTTP è¾“å‡ºï¼‰
	addr := fmt.Sprintf("%s:%d", config.Server.Host, config.Server.Port)
	log.Printf("ğŸš€ è½¬æ¢å™¨å¯åŠ¨åœ¨ %s", addr)
	log.Printf("ğŸ“Š ClickHouse: %s:%d/%s.%s", config.ClickHouse.Host, config.ClickHouse.Port, config.ClickHouse.Database, config.ClickHouse.Table)
	
	// å¯åŠ¨å…¶ä»–è¾“å…¥æº
	if config.Inputs.Logstash.Enabled {
		go startLogstashTCP(config.Inputs.Logstash.Port)
	}
	if config.Inputs.Kafka.Enabled {
		go startKafkaConsumer()
	}
	if config.Inputs.Redis.Enabled {
		go startRedisConsumer()
	}
	if config.Inputs.File.Enabled {
		go startFileTail()
	}
	if config.Inputs.TCP.Enabled {
		go startTCPServer()
	}
	
	if err := r.Run(addr); err != nil {
		log.Fatalf("æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: %v", err)
	}
}

// loadConfig åŠ è½½é…ç½®æ–‡ä»¶
func loadConfig() error {
	configPath := os.Getenv("CONFIG_PATH")
	if configPath == "" {
		configPath = "/etc/filebeat-to-ck/config.yaml"
	}

	data, err := os.ReadFile(configPath)
	if err != nil {
		return fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	if err := yaml.Unmarshal(data, &config); err != nil {
		return fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// è®¾ç½®é»˜è®¤å€¼
	if config.Server.Host == "" {
		config.Server.Host = "0.0.0.0"
	}
	if config.Server.Port == 0 {
		config.Server.Port = 8080
	}
	if config.ClickHouse.Host == "" {
		config.ClickHouse.Host = "clickhouse"
	}
	if config.ClickHouse.Port == 0 {
		config.ClickHouse.Port = 8123
	}
	if config.ClickHouse.Database == "" {
		config.ClickHouse.Database = "logs"
	}
	if config.ClickHouse.Table == "" {
		config.ClickHouse.Table = "logs_table"
	}

	return nil
}

// healthCheck å¥åº·æ£€æŸ¥
func healthCheck(c *gin.Context) {
	c.JSON(http.StatusOK, gin.H{
		"status":  "ok",
		"service": "filebeat-to-clickhouse",
		"time":    time.Now().Format(time.RFC3339),
	})
}

// handleBulk å¤„ç† Elasticsearch bulk API æ ¼å¼
// Filebeat å‘é€çš„æ ¼å¼ï¼šæ¯ä¸¤è¡Œä¸€ç»„ï¼Œç¬¬ä¸€è¡Œæ˜¯ actionï¼Œç¬¬äºŒè¡Œæ˜¯ document
func handleBulk(c *gin.Context) {
	body, err := io.ReadAll(c.Request.Body)
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "è¯»å–è¯·æ±‚ä½“å¤±è´¥"})
		return
	}

	// è§£æ bulk æ ¼å¼ï¼ˆæ¯ä¸¤è¡Œä¸€ç»„ï¼šaction + documentï¼‰
	lines := strings.Split(string(body), "\n")
	var events []FilebeatEvent

	for i := 0; i < len(lines); i++ {
		line := strings.TrimSpace(lines[i])
		if line == "" {
			continue
		}

		// å°è¯•è§£æä¸º actionï¼ˆindex, create, update, deleteï¼‰
		var action map[string]interface{}
		if err := json.Unmarshal([]byte(line), &action); err != nil {
			// å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œè·³è¿‡
			continue
		}

		// æ£€æŸ¥æ˜¯å¦æ˜¯ action è¡Œï¼ˆåŒ…å« index, create, update, delete ç­‰é”®ï¼‰
		isAction := false
		for key := range action {
			if key == "index" || key == "create" || key == "update" || key == "delete" {
				isAction = true
				break
			}
		}

		// å¦‚æœä¸æ˜¯ action è¡Œï¼Œå¯èƒ½æ˜¯ document è¡Œï¼ˆå¤„ç†å¼‚å¸¸æƒ…å†µï¼‰
		if !isAction {
			// ç›´æ¥ä½œä¸º document å¤„ç†
			var event FilebeatEvent
			if err := json.Unmarshal([]byte(line), &event); err != nil {
				// å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä½œä¸ºé€šç”¨ JSON å¤„ç†
				var generic map[string]interface{}
				if err := json.Unmarshal([]byte(line), &generic); err == nil {
					event = convertGenericToEvent(generic)
					events = append(events, event)
				}
			} else {
				events = append(events, event)
			}
			continue
		}

		// æ˜¯ action è¡Œï¼Œä¸‹ä¸€è¡Œåº”è¯¥æ˜¯ document
		if i+1 < len(lines) {
			i++
			docLine := strings.TrimSpace(lines[i])
			if docLine == "" {
				continue
			}

			var event FilebeatEvent
			if err := json.Unmarshal([]byte(docLine), &event); err != nil {
				// å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä½œä¸ºé€šç”¨ JSON å¤„ç†
				var generic map[string]interface{}
				if err := json.Unmarshal([]byte(docLine), &generic); err == nil {
					event = convertGenericToEvent(generic)
				} else {
					// è§£æå¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ª document
					continue
				}
			}

			events = append(events, event)
		}
	}

	// æ‰¹é‡å†™å…¥ ClickHouse
	if len(events) > 0 {
		if err := writeToClickHouse(events); err != nil {
			log.Printf("å†™å…¥ ClickHouse å¤±è´¥: %v", err)
			c.JSON(http.StatusInternalServerError, gin.H{"error": "å†™å…¥å¤±è´¥"})
			return
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"took":   len(events),
		"errors": false,
		"items":  len(events),
	})
}

// handleEvents å¤„ç†ç›´æ¥ JSON äº‹ä»¶æ•°ç»„
func handleEvents(c *gin.Context) {
	var events []FilebeatEvent
	if err := c.ShouldBindJSON(&events); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "æ— æ•ˆçš„ JSON æ ¼å¼"})
		return
	}

	if err := writeToClickHouse(events); err != nil {
		log.Printf("å†™å…¥ ClickHouse å¤±è´¥: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{"error": "å†™å…¥å¤±è´¥"})
		return
	}

	c.JSON(http.StatusOK, gin.H{"status": "ok", "count": len(events)})
}

// handleFilebeat å¤„ç† Filebeat ç›´æ¥è¾“å‡º
func handleFilebeat(c *gin.Context) {
	var event FilebeatEvent
	if err := c.ShouldBindJSON(&event); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "æ— æ•ˆçš„ JSON æ ¼å¼"})
		return
	}

	events := []FilebeatEvent{event}
	if err := writeToClickHouse(events); err != nil {
		log.Printf("å†™å…¥ ClickHouse å¤±è´¥: %v", err)
		c.JSON(http.StatusInternalServerError, gin.H{"error": "å†™å…¥å¤±è´¥"})
		return
	}

	c.JSON(http.StatusOK, gin.H{"status": "ok"})
}

// convertGenericToEvent å°†é€šç”¨ JSON è½¬æ¢ä¸ºäº‹ä»¶
func convertGenericToEvent(generic map[string]interface{}) FilebeatEvent {
	event := FilebeatEvent{
		Fields:    make(map[string]interface{}),
		Container: make(map[string]interface{}),
		Host:      make(map[string]interface{}),
		Docker:    make(map[string]interface{}),
		Agent:     make(map[string]interface{}),
		Log:       make(map[string]interface{}),
		Extra:     make(map[string]interface{}),
	}

	// æå–æ—¶é—´æˆ³
	if ts, ok := generic["@timestamp"]; ok {
		event.Timestamp = ts
	}

	// æå–æ¶ˆæ¯
	if msg, ok := generic["message"].(string); ok {
		event.Message = msg
	}

	// æå–å…¶ä»–å­—æ®µ
	for k, v := range generic {
		switch k {
		case "@timestamp", "message":
			continue
		case "container":
			if m, ok := v.(map[string]interface{}); ok {
				event.Container = m
			}
		case "host":
			if m, ok := v.(map[string]interface{}); ok {
				event.Host = m
			}
		case "docker":
			if m, ok := v.(map[string]interface{}); ok {
				event.Docker = m
			}
		case "agent":
			if m, ok := v.(map[string]interface{}); ok {
				event.Agent = m
			}
		case "log":
			if m, ok := v.(map[string]interface{}); ok {
				event.Log = m
			}
		default:
			event.Extra[k] = v
		}
	}

	return event
}

// writeToClickHouse å†™å…¥æ•°æ®åˆ° ClickHouse
func writeToClickHouse(events []FilebeatEvent) error {
	if len(events) == 0 {
		return nil
	}

	// æ„å»º JSONEachRow æ ¼å¼çš„æ•°æ®
	var jsonLines []string
	for _, event := range events {
		// æ„å»º ClickHouse è®°å½•
		record := make(map[string]interface{})
		
		// æ—¶é—´æˆ³
		timestamp := event.GetTimestamp()
		record["timestamp"] = timestamp.Format("2006-01-02 15:04:05")

		// æ¶ˆæ¯
		record["message"] = event.Message

		// å®¹å™¨ä¿¡æ¯
		if event.Container != nil {
			if name, ok := event.Container["name"].(string); ok {
				record["container"] = name
			} else if id, ok := event.Container["id"].(string); ok {
				record["container"] = id
			}
		}

		// ä¸»æœºä¿¡æ¯
		if event.Host != nil {
			if name, ok := event.Host["name"].(string); ok {
				record["host_name"] = name
			}
		}

		// Docker ä¿¡æ¯
		if event.Docker != nil {
			if container, ok := event.Docker["container"].(map[string]interface{}); ok {
				if id, ok := container["id"].(string); ok {
					record["docker_container_id"] = id
				}
				if name, ok := container["name"].(string); ok {
					record["docker_container_name"] = name
				}
			}
		}

		// Agent ä¿¡æ¯
		if event.Agent != nil {
			if name, ok := event.Agent["name"].(string); ok {
				record["agent_name"] = name
			}
			if version, ok := event.Agent["version"].(string); ok {
				record["agent_version"] = version
			}
		}

		// Log ä¿¡æ¯
		if event.Log != nil {
			if path, ok := event.Log["file"].(map[string]interface{}); ok {
				if p, ok := path["path"].(string); ok {
					record["log_file_path"] = p
				}
			}
		}

		// å°†æ•´ä¸ªäº‹ä»¶åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼ˆå­˜å‚¨åœ¨ raw_json å­—æ®µï¼‰
		if eventJson, err := json.Marshal(event); err == nil {
			record["raw_json"] = string(eventJson)
		}

		// è½¬æ¢ä¸º JSON è¡Œ
		if jsonBytes, err := json.Marshal(record); err == nil {
			jsonLines = append(jsonLines, string(jsonBytes))
		}
	}

	// æ„å»º ClickHouse INSERT è¯·æ±‚
	// ä½¿ç”¨ URL ç¼–ç ç¡®ä¿å®‰å…¨
	query := fmt.Sprintf("INSERT INTO %s.%s FORMAT JSONEachRow", config.ClickHouse.Database, config.ClickHouse.Table)
	encodedQuery := url.QueryEscape(query)
	requestURL := fmt.Sprintf("http://%s:%d/?query=%s", config.ClickHouse.Host, config.ClickHouse.Port, encodedQuery)
	
	data := strings.Join(jsonLines, "\n")
	req, err := http.NewRequest("POST", requestURL, bytes.NewBufferString(data))
	if err != nil {
		return fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	// ClickHouse JSONEachRow æ ¼å¼ä¸éœ€è¦ç‰¹å®šçš„ Content-Type
	// ä½†è®¾ç½®ä¸€ä¸ªé€šç”¨çš„ç±»å‹æœ‰åŠ©äºè¯†åˆ«
	req.Header.Set("Content-Type", "application/x-ndjson")
	if config.ClickHouse.User != "" {
		req.SetBasicAuth(config.ClickHouse.User, config.ClickHouse.Password)
	}

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("ClickHouse è¿”å›é”™è¯¯: %d, %s", resp.StatusCode, string(body))
	}

	log.Printf("âœ… æˆåŠŸå†™å…¥ %d æ¡è®°å½•åˆ° ClickHouse", len(events))
	return nil
}

// handleLogstash å¤„ç† Logstash HTTP è¾“å‡º
// Filebeat output.logstash å¯ä»¥é…ç½®ä¸º HTTP è¾“å‡º
func handleLogstash(c *gin.Context) {
	// Logstash HTTP è¾“å‡ºé€šå¸¸æ˜¯ JSON æ ¼å¼
	body, err := io.ReadAll(c.Request.Body)
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "è¯»å–è¯·æ±‚ä½“å¤±è´¥"})
		return
	}

	// å°è¯•è§£æä¸ºå•ä¸ªäº‹ä»¶æˆ–äº‹ä»¶æ•°ç»„
	var events []FilebeatEvent
	
	// å…ˆå°è¯•ä½œä¸ºæ•°ç»„è§£æ
	var eventArray []map[string]interface{}
	if err := json.Unmarshal(body, &eventArray); err == nil {
		// æ˜¯æ•°ç»„
		for _, item := range eventArray {
			event := convertGenericToEvent(item)
			events = append(events, event)
		}
	} else {
		// å°è¯•ä½œä¸ºå•ä¸ªäº‹ä»¶
		var event FilebeatEvent
		if err := json.Unmarshal(body, &event); err == nil {
			events = append(events, event)
		} else {
			// å°è¯•ä½œä¸ºé€šç”¨ JSON
			var generic map[string]interface{}
			if err := json.Unmarshal(body, &generic); err == nil {
				event := convertGenericToEvent(generic)
				events = append(events, event)
			} else {
				c.JSON(http.StatusBadRequest, gin.H{"error": "æ— æ•ˆçš„ JSON æ ¼å¼"})
				return
			}
		}
	}

	// å†™å…¥ ClickHouse
	if len(events) > 0 {
		if err := writeToClickHouse(events); err != nil {
			log.Printf("å†™å…¥ ClickHouse å¤±è´¥: %v", err)
			c.JSON(http.StatusInternalServerError, gin.H{"error": "å†™å…¥å¤±è´¥"})
			return
		}
	}

	c.JSON(http.StatusOK, gin.H{"status": "ok", "count": len(events)})
}

// startLogstashTCP å¯åŠ¨ Logstash TCP æœåŠ¡å™¨ï¼ˆLumberjack/Beats protocolï¼‰
func startLogstashTCP(port int) {
	log.Printf("ğŸ“¡ å¯åŠ¨ Logstash TCP æœåŠ¡å™¨åœ¨ç«¯å£ %d", port)
	// TODO: å®ç° Lumberjack/Beats protocol æ”¯æŒ
	// è¿™æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶åè®®ï¼Œéœ€è¦ä¸“é—¨çš„åº“æ¥è§£æ
	log.Printf("âš ï¸  Logstash TCP åè®®æ”¯æŒéœ€è¦é¢å¤–çš„åº“ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒ")
}

// startKafkaConsumer å¯åŠ¨ Kafka consumer
func startKafkaConsumer() {
	if len(config.Inputs.Kafka.Brokers) == 0 || len(config.Inputs.Kafka.Topics) == 0 {
		log.Printf("âš ï¸  Kafka é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡å¯åŠ¨")
		return
	}
	log.Printf("ğŸ“¡ å¯åŠ¨ Kafka consumer: brokers=%v, topics=%v", config.Inputs.Kafka.Brokers, config.Inputs.Kafka.Topics)
	// TODO: å®ç° Kafka consumer
	// éœ€è¦ä½¿ç”¨ kafka-go åº“
	log.Printf("âš ï¸  Kafka consumer æ”¯æŒéœ€è¦é¢å¤–çš„åº“ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒ")
}

// startRedisConsumer å¯åŠ¨ Redis consumer
func startRedisConsumer() {
	if config.Inputs.Redis.Address == "" || config.Inputs.Redis.Key == "" {
		log.Printf("âš ï¸  Redis é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡å¯åŠ¨")
		return
	}
	log.Printf("ğŸ“¡ å¯åŠ¨ Redis consumer: address=%s, mode=%s, key=%s", config.Inputs.Redis.Address, config.Inputs.Redis.Mode, config.Inputs.Redis.Key)
	// TODO: å®ç° Redis LIST/PUBSUB consumer
	// éœ€è¦ä½¿ç”¨ go-redis åº“
	log.Printf("âš ï¸  Redis consumer æ”¯æŒéœ€è¦é¢å¤–çš„åº“ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒ")
}

// startFileTail å¯åŠ¨æ–‡ä»¶ tail
func startFileTail() {
	if len(config.Inputs.File.Paths) == 0 {
		log.Printf("âš ï¸  æ–‡ä»¶è·¯å¾„é…ç½®ä¸ºç©ºï¼Œè·³è¿‡å¯åŠ¨")
		return
	}
	log.Printf("ğŸ“¡ å¯åŠ¨æ–‡ä»¶ tail: paths=%v", config.Inputs.File.Paths)
	// TODO: å®ç°æ–‡ä»¶ tail
	// å¯ä»¥ä½¿ç”¨ fsnotify åº“ç›‘æ§æ–‡ä»¶å˜åŒ–
	log.Printf("âš ï¸  æ–‡ä»¶ tail æ”¯æŒéœ€è¦é¢å¤–çš„åº“ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒ")
}

// startTCPServer å¯åŠ¨ TCP æœåŠ¡å™¨
func startTCPServer() {
	if config.Inputs.TCP.Port == 0 {
		log.Printf("âš ï¸  TCP ç«¯å£æœªé…ç½®ï¼Œè·³è¿‡å¯åŠ¨")
		return
	}
	log.Printf("ğŸ“¡ å¯åŠ¨ TCP æœåŠ¡å™¨åœ¨ç«¯å£ %d, æ ¼å¼=%s", config.Inputs.TCP.Port, config.Inputs.TCP.Format)
	// TODO: å®ç° TCP æœåŠ¡å™¨
	// æ”¯æŒ JSON å’Œ JSON Lines æ ¼å¼
	log.Printf("âš ï¸  TCP æœåŠ¡å™¨æ”¯æŒéœ€è¦é¢å¤–å®ç°ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒ")
}

